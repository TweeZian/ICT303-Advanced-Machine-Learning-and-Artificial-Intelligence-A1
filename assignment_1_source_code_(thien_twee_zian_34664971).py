# -*- coding: utf-8 -*-
"""Assignment 1 Source Code (Thien Twee Zian - 34664971).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K_BPpQrYAH6WDFsuLURwS4urNvtnlVAA

# Dependencies and Initial Setup
"""

# Commented out IPython magic to ensure Python compatibility.
## Dependencies and Initial Setup

# 1. PyTorch and TorchVision
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import datasets, transforms, models
from torchvision.models import VGG16_Weights

# 2. Keras and TensorFlow
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, ReLU, Dropout, Input
from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping

# 3. Data Manipulation and Visualization
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

# 4. Sklearn Utilities
from sklearn.metrics import precision_score, confusion_matrix
from sklearn.model_selection import train_test_split

# 5. TensorBoard Utilities
from torch.utils.tensorboard import SummaryWriter
from torch.optim.lr_scheduler import ReduceLROnPlateau

# 6. Load Dataset from GitHub (comment out if not needed for execution)
!git clone https://github.com/TweeZian/ICT303-A1-Dataset.git

# 7. Load TensorBoard extension (for Jupyter Notebook)
# %load_ext tensorboard

"""# Common Classes"""

# Data Class
# Transforms to apply to the data
def get_transforms(width, height):
    return transforms.Compose([
        transforms.Resize((height, width)),  # Resize to the given height and width
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

# For changing dataloader from Tensor to numpy
def data_loader_to_numpy(loader):
    images, labels = [], []
    for img, label in loader:
        images.append(img.numpy())  # Convert tensor to numpy array
        labels.append(label.numpy())  # Convert tensor to numpy array
    images = np.concatenate(images)  # Combine all image batches into one array
    labels = np.concatenate(labels)  # Combine all label batches into one array

    # Transpose the images to (N, H, W, C)
    images = np.transpose(images, (0, 2, 3, 1))  # Change from (N, C, H, W) to (N, H, W, C)
    return images, labels

# Loading the data
trainset_path = '/content/ICT303-A1-Dataset/data/train'
valset_path = '/content/ICT303-A1-Dataset/data/valid'

# For testing and evaluation
class Tester:
    def __init__(self, model):
        self.model = model
        self.categories = ['accessories', 'jackets', 'jeans', 'knitwear', 'shirts', 'shoes', 'shorts', 'tees']
        self.label_map = {label: idx for idx, label in enumerate(self.categories)}

    def evaluate(self, predicted_classes, true_classes):
        # Calculate precision (for weighted precision score)
        precision = precision_score(true_classes, predicted_classes, average='weighted', zero_division=0)

        # Confusion Matrix
        cm = confusion_matrix(true_classes, predicted_classes, labels=np.arange(len(self.categories)))

        return precision, cm

    def plot_confusion_matrix(self, cm, precision):
        plt.figure(figsize=(8, 8))
        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title("Confusion Matrix")
        plt.colorbar()

        # Ticks and labels
        tick_marks = np.arange(len(self.categories))
        plt.xticks(tick_marks, self.categories, rotation=45, ha='right')
        plt.yticks(tick_marks, self.categories)

        # Add text annotations in each cell
        thresh = cm.max() / 2
        for i, j in np.ndindex(cm.shape):
            plt.text(j, i, format(cm[i, j], 'd'),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.figtext(0.5, -0.05, f'Mean Average Precision: {precision:.4f}', ha='center', fontsize=12)
        plt.tight_layout()
        plt.show()

"""# Question 1

Develop a multilayer perceptron model, train it and test it on the dataset. You need to finetune the hyperparameters to select those that provide the best performance. [40 Marks]
"""

# Load datasets
# Datasets are loaded seperately between questions due to the size (W x B)
width = 32
height = 32
input_size = (height, width, 3)

transform = get_transforms(width=width, height=height)
train_dataset = datasets.ImageFolder(root=trainset_path, transform=transform)
test_dataset = datasets.ImageFolder(root=valset_path, transform=transform)
trainloader = DataLoader(train_dataset, shuffle=True, num_workers=1)
testloader = DataLoader(test_dataset, shuffle=False, num_workers=1)

# Convert DataLoaders to numpy arrays
train_data, train_label = data_loader_to_numpy(trainloader)
test_data, test_label = data_loader_to_numpy(testloader)

# Convert to one-hot encoding
train_label = tf.keras.utils.to_categorical(train_label, num_classes=8)
test_label = tf.keras.utils.to_categorical(test_label, num_classes=8)

# Split the original training data into training and validation sets
train_data, val_data, train_label, val_label = train_test_split(
    train_data, train_label,
    test_size=0.2,   # 20% of the data will be used for validation
    random_state=42   # For reproducibility
)

def MLP(input_size=(32, 32, 3), output_size=8, optimizer=None, loss=None):
    model = Sequential()
    model.add(Input(shape=input_size))
    model.add(Flatten())

    model.add(Dense(4096))
    model.add(ReLU())
    model.add(Dropout(0.5))

    model.add(Dense(2048))
    model.add(ReLU())
    model.add(Dropout(0.5))

    model.add(Dense(1024))
    model.add(ReLU())
    model.add(Dropout(0.5))

    model.add(Dense(output_size,activation='softmax'))

    # Compile the model with optimizer, loss, and metrics
    model.compile(
        optimizer=optimizer,
        loss=loss,
        metrics=['accuracy']
    )

    return model

# Hyper-parameters
epoch = 50
lr = 1e-04
batch_size = 16

# Loss and optimizer
weight_decay=0.01
optimizer=tf.keras.optimizers.Adam(learning_rate=lr,weight_decay=weight_decay)
loss='categorical_crossentropy'

# Callback creations (Tensorboard, ReduceLROnPlateau & EarlyStopping)
log_dir = 'model_training/Q1'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Main Program
model = MLP(input_size=input_size, optimizer=optimizer, loss=loss)
history = model.fit(train_data, train_label,
                    epochs=epoch,
                    batch_size=batch_size,
                    validation_data=(val_data, val_label),
                    callbacks=[tensorboard_callback, reduce_lr, early_stopping])

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir model_training/Q1

test_loss, test_acc = model.evaluate(test_data, test_label)
print(f'Test Loss: {test_loss:.4f}')
print(f'Test Accuracy: {test_acc:.4f}')

# Evaluation and Confusion Matrix
tester = Tester(model=model)

# Predictions and converting to class indices from one-hot
predictions = model.predict(test_data)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(test_label, axis=1)

# Evaluate the test set
precision, cm = tester.evaluate(predicted_classes, true_classes)

# Plot the confusion matrix
tester.plot_confusion_matrix(cm, precision)

"""# Question 2

Implement VGG16, which a CNN architecture, train it and test it on the dataset. You must NOT use the pre-implemented VGG16 network in Pytorch. Instead, you have to implement all the layers and blocks yourself from scratch. You need to finetune the hyperparameters to select those that provide the best performance. [40 Marks]
"""

# Load datasets
# Datasets are loaded seperately between questions due to the size (W x B)
width = 224
height = 224
input_size = (height, width, 3)

transform = get_transforms(width=width, height=height)
train_dataset = datasets.ImageFolder(root=trainset_path, transform=transform)
test_dataset = datasets.ImageFolder(root=valset_path, transform=transform)
trainloader = DataLoader(train_dataset, shuffle=True, num_workers=1)
testloader = DataLoader(test_dataset, shuffle=False, num_workers=1)

# Convert DataLoaders to numpy arrays
train_data, train_label = data_loader_to_numpy(trainloader)
test_data, test_label = data_loader_to_numpy(testloader)

# Convert to one-hot encoding
train_label = tf.keras.utils.to_categorical(train_label, num_classes=8)
test_label = tf.keras.utils.to_categorical(test_label, num_classes=8)

# Split the original training data into training and validation sets
train_data, val_data, train_label, val_label = train_test_split(
    train_data, train_label,
    test_size=0.2,   # 20% of the data will be used for validation
    random_state=42   # For reproducibility
)

def build_VGG16(input_size=(224, 224, 3), output_size=8, optimizer=None, loss=None):
    model = Sequential()
    model.add(Input(shape=input_size))

    # Block 1
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Block 2
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Block 3
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Block 4
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Block 5
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Fully Connected Layers
    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(8, activation='softmax'))  # 8 for your categories

    # Compile the model with optimizer, loss, and metrics
    model.compile(
        optimizer=optimizer,
        loss=loss,
        metrics=['accuracy']
    )

    return model

# Hyper-parameters
epoch = 50
lr = 1e-04
batch_size = 16

# Loss and optimizer
weight_decay=0.01
optimizer=tf.keras.optimizers.Adam(learning_rate=lr,weight_decay=weight_decay)
loss='categorical_crossentropy'

# Callback creations (Tensorboard, ReduceLROnPlateau & EarlyStopping)
log_dir = 'model_training/Q2'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Main Program
model = build_VGG16(input_size=input_size, optimizer=optimizer, loss=loss)
history = model.fit(train_data, train_label,
                    epochs=epoch,
                    batch_size=batch_size,
                    validation_data=(val_data, val_label),
                    callbacks=[tensorboard_callback, reduce_lr, early_stopping])

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir model_training/Q2

test_loss, test_acc = model.evaluate(val_data, val_label)
print(f'Test Loss: {test_loss:.4f}')
print(f'Test Accuracy: {test_acc:.4f}')

# Evaluation and Confusion Matrix
tester = Tester(model=model)

# Predictions and converting to class indices from one-hot
predictions = model.predict(val_data)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(val_label, axis=1)

# Evaluate the test set
precision, cm = tester.evaluate(predicted_classes, true_classes)

# Plot the confusion matrix
tester.plot_confusion_matrix(cm, precision)

"""# Question 3

Repeat step 2 above , but this time using the pretrained VGG16 network of PyTorch. [20 Marks]
"""

width = 224
height = 224
input_size = (height, width, 3)
batch_size = 32
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Preparing the data
transform = get_transforms(width=224, height=224)
train_dataset = datasets.ImageFolder(root=trainset_path, transform=transform)
test_dataset = datasets.ImageFolder(root=valset_path, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1) # Batch size 8 due to no. of test samples only 8

# Calculate the sizes for train and validation sets
train_size = int(0.8 * len(train_dataset))  # 80% for training
val_size = len(train_dataset) - train_size   # 20% for validation

# Split the dataset into training and validation datasets
train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])

# Create DataLoaders for training and validation sets
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Evaluation function
def evaluate_model(model, dataloader, tester, criterion):
    model.eval()  # Set model to evaluation mode
    predicted_classes = []
    true_classes = []

    test_loss = 0.0
    correct_predictions = 0
    total_samples = 0

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in dataloader:
            images = images.to(device)
            labels = labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Accumulate loss
            test_loss += loss.item() * images.size(0)

            # Get predicted classes
            _, preds = torch.max(outputs, 1)

            # Track predictions and true labels
            predicted_classes.extend(preds.cpu().numpy())
            true_classes.extend(labels.cpu().numpy())

            # Update correct predictions and total samples
            correct_predictions += (preds == labels).sum().item()
            total_samples += labels.size(0)

    # Calculate average loss and accuracy
    avg_test_loss = test_loss / total_samples
    test_accuracy = correct_predictions / total_samples

    # Precision and Confusion Matrix using the Tester class
    precision, cm = tester.evaluate(predicted_classes, true_classes)

    # Print results
    print(f'Test Loss: {avg_test_loss:.4f}')
    print(f'Test Accuracy: {test_accuracy:.4f}')
    print(f'Precision: {precision:.4f}')

    # Plot the confusion matrix using Tester class
    tester.plot_confusion_matrix(cm, precision)

    return avg_test_loss, test_accuracy, precision, cm

# Load pre-trained VGG16
model = models.vgg16()

# Modify the classifier to match the number of classes
model.classifier[6] = nn.Linear(4096, 8)  # Assuming 8 classes in the output
model = model.to(device)  # Move the model to the GPU if available

# Hyperparameters
num_epochs = 50
lr = 1e-4
weight_decay = 0.01

optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
criterion = nn.CrossEntropyLoss()

# TensorBoard setup
log_dir = 'model_training/Q3'
writer = SummaryWriter(log_dir=log_dir)

# Early Stopping parameters
patience = 5  # Number of epochs to wait for improvement
best_val_loss = float('inf')  # Initialize best validation loss
patience_counter = 0  # Initialize patience counter

# Learning rate scheduler
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e-6)

# Initialize TensorBoard SummaryWriter
writer = SummaryWriter(log_dir='model_training/Q3')  # Specify the log directory

# Trainer
for epoch in range(num_epochs):
    model.train()  # Set the model to training mode
    running_loss = 0.0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Track training accuracy
        _, predicted = torch.max(outputs, 1)
        correct_train += (predicted == labels).sum().item()
        total_train += labels.size(0)

    train_loss = running_loss / len(train_loader)
    train_acc = correct_train / total_train

    # Validation phase
    model.eval()  # Set the model to evaluation mode
    val_loss = 0.0
    correct_val = 0
    total_val = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            # Track validation accuracy
            _, predicted = torch.max(outputs, 1)
            correct_val += (predicted == labels).sum().item()
            total_val += labels.size(0)

    val_loss = val_loss / len(val_loader)
    val_acc = correct_val / total_val

    # Log metrics to TensorBoard
    writer.add_scalar('Loss/Train', train_loss, epoch)
    writer.add_scalar('Loss/Validation', val_loss, epoch)
    writer.add_scalar('Accuracy/Train', train_acc, epoch)
    writer.add_scalar('Accuracy/Validation', val_acc, epoch)

    # Print metrics for this epoch
    print(f"Epoch {epoch+1}")
    print(f"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc*100:.2f}%")
    print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc*100:.2f}%\n")

    # Step the scheduler with the validation loss
    scheduler.step(val_loss)

    # Early Stopping check
    if val_loss < best_val_loss:
        best_val_loss = val_loss  # Update the best validation loss
        patience_counter = 0  # Reset patience counter
    else:
        patience_counter += 1  # Increment patience counter

    # Check if patience has been exceeded
    if patience_counter >= patience:
        print(f"Early stopping triggered at epoch {epoch+1}")
        break  # Stop training

# Close the TensorBoard writer
writer.close()

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir model_training/Q3

tester = Tester(model)
test_loss, test_acc, precision, cm = evaluate_model(model, test_loader, tester, criterion)